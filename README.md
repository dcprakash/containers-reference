
# Dockerized Frontend-Backend Application with OpenAI Integration

This repository contains a simple two-app setup using Docker. It consists of a frontend application built with Streamlit and a backend application built with Flask. The frontend app allows users to input a message, which is sent to the backend. The backend processes this message using the OpenAI API to generate a response, which is then displayed back to the user on the frontend.

## Project Structure
```
.
├── backend/
│   ├── app.py             # Flask application that communicates with OpenAI
│   └── Dockerfile         # Dockerfile for building the backend container
├── frontend/
│   ├── app.py             # Streamlit application that interacts with the backend
│   └── Dockerfile         # Dockerfile for building the frontend container
└── docker-compose.yml     # Docker Compose file to run both containers together
```

### Backend Application

The backend is a Flask application that listens for POST requests from the frontend. It forwards the received message to the OpenAI API and returns the generated response to the frontend.

### Frontend Application

The frontend is a Streamlit application that provides a simple UI for users to input a message. This message is sent to the backend, and the response from the backend is displayed to the user.

## Prerequisites

- Docker installed on your local machine
- An OpenAI API key

## Setting Up and Running the Application

### Step 1: Set the OpenAI API Key

Before running the application, you need to set the `OPENAI_API_KEY` environment variable on your local machine. This key will be passed into the backend container when it runs.

#### On Linux/MacOS:

```bash
export OPENAI_API_KEY="your_openai_api_key_here"
```

#### On Windows (Powershell):
```bash
$env:OPENAI_API_KEY="your_openai_api_key_here"
```

### Step 2: Run the Application Using Docker Compose

To start the application, navigate to the root directory of the project where the `docker-compose.yml` file is located and run:

```bash
docker-compose up --build
```

This command will:

- Build and run the backend service (Flask app) on port 8080.
- Build and run the frontend service (Streamlit app) on port 5173.

### How Docker Compose Works

- **Service Communication:** The `docker-compose.yml` file defines two services: frontend and backend. Docker Compose automatically creates a network that allows these services to communicate with each other using their service names.

    - The frontend sends a request to the backend using the URL `http://backend:8080/message`.
    - Docker Compose resolves `backend` to the appropriate container's IP address.

- **Environment Variables:** The `OPENAI_API_KEY` environment variable is loaded from your host machine into the backend container. This allows the backend to securely access the OpenAI API without hardcoding the key into the code or the Docker Compose file.

### Step 3: Access the Application

Once the containers are up and running, open your web browser and go to:

[http://localhost:5173](http://localhost:5173)

You should see the frontend application where you can enter a message and receive a response generated by OpenAI.

### Stopping the Application

To stop the running containers, use `Ctrl+C` in the terminal where `docker-compose up` is running. You can also stop and remove the containers with:

```bash
docker-compose down
```
